# ü§ñ Cursor Agent Prompt - MedExamAI (Neuer Mac)

**Erstellt:** 2025-12-18
**Repo-Pfad:** `/Users/entropie/Documents/Medexamenai_Migration/Medexamenai_migration_full_20251217_204617`
**Status:** Migration abgeschlossen, bereit f√ºr Entwicklung

---

## üìã Quick Start Checklist

Bevor du startest, lies diese Dateien in dieser Reihenfolge:

1. ‚úÖ [AGENT_OVERVIEW.md](AGENT_OVERVIEW.md) - Harte Constraints & Repo-Struktur
2. ‚úÖ [PROJECT_STATUS.md](PROJECT_STATUS.md) - Aktueller Projektstatus
3. ‚úÖ [TODO.md](TODO.md) - Priorisierte Aufgabenliste
4. ‚úÖ Diese Datei - Handlungsanweisungen

---

## üö® HARTE REGELN (NIEMALS BRECHEN!)

### 1. READ-ONLY Dateien

```bash
# NIEMALS √ºberschreiben oder direkt editieren:
_OUTPUT/evidenz_antworten.json  # Kanonische Q&A-Datenbank (4.505 Eintr√§ge)
```

**Warum?** Dies ist die Source of Truth. Alle Updates erfolgen √ºber dedizierte Scripts mit Timestamp-Outputs.

### 2. Output-Konvention

```bash
# Alle neuen Outputs IMMER mit Timestamp schreiben:
_OUTPUT/neue_datei_$(date +%Y%m%d_%H%M%S).json

# Beispiel:
_OUTPUT/batch_review_report_20251218_153045.json
```

### 3. Secrets & Credentials

```bash
# .env existiert - NIEMALS loggen, committen oder anzeigen
# API Keys f√ºr: OpenAI, Anthropic, Perplexity
cat .env  # ‚ùå NIEMALS in Logs/Commits

# Pr√ºfen ob Keys gesetzt sind (ohne Werte anzuzeigen):
grep -E "^(OPENAI|ANTHROPIC|PERPLEXITY)" .env | wc -l  # Sollte ‚â• 2-3 sein
```

### 4. Python Environment

```bash
# Immer im venv arbeiten:
source venv/bin/activate

# Vor jedem Script-Run pr√ºfen:
which python3  # Sollte: /Users/entropie/.../venv/bin/python3
```

---

## üìä Aktueller Datenstand (Stand: 2025-12-16)

### Kanonische Datenbank

| Datei | Eintr√§ge | Status | Aktion |
|-------|----------|--------|--------|
| `_OUTPUT/evidenz_antworten.json` | 4.505 | READ-ONLY ‚úÖ | Niemals editieren |
| `_OUTPUT/evidenz_antworten_updated_20251216_142834.json` | 4.505 | Arbeitsdatei üìù | Enth√§lt Batch-Updates |

### Review-Queue Status

| Kategorie | Anzahl | Datei |
|-----------|--------|-------|
| Gesamt Review Items | 431 | `_OUTPUT/review_queue_20251216_033807.json` |
| ‚îú‚îÄ needs_review | 298 | In Batch verarbeitet |
| ‚îî‚îÄ needs_context | 133 | Bereits gematcht |
| **needs_context (prepared)** | 133/133 | `_OUTPUT/needs_context_prepared_20251216_054003.json` |

### Batch-Review Pipeline (Run: 20251216_064700)

| Status | Anzahl | Datei |
|--------|--------|-------|
| ‚úÖ OK | 285 | `_OUTPUT/batch_corrected_20251216_064700.json` |
| ‚ö†Ô∏è Maybe | 79 | `_OUTPUT/batch_validated_20251216_064700.json` |
| ‚ùå Problem | **67** | `_OUTPUT/batch_review_remaining_issues_20251216_142834.json` |

### Coverage-Status

| Metrik | Wert | Datei |
|--------|------|-------|
| Meaningful Missing | 2.527 | `_OUTPUT/meaningful_missing.json` |
| **Coverage** | **2.527/2.527 = 100%** ‚úÖ | Alle meaningful Fragen vorhanden |
| Strict Missing (historisch) | 3.732 | `_OUTPUT/questions_missing_strict.json` (ignorieren!) |

**Wichtig:** `questions_missing_strict.json` (3.732) ist eine **alte, zu strenge** Analyse mit vielen Fragmenten/Duplikaten. **Nicht verwenden!** Die authoritative Liste ist `meaningful_missing.json` mit 100% Coverage.

---

## üéØ Priorisierte Aufgaben (Nach Wichtigkeit)

### üî¥ H√ñCHSTE PRIORIT√ÑT: 67 Problem-Items fixen

**Datei:** `_OUTPUT/batch_review_remaining_issues_20251216_142834.json`
**Anzahl:** 67 Items mit `verdict: "problem"`
**Ziel:** Manuelle oder zweite Batch-Runde zur Korrektur

**Vorgehen:**

```bash
# 1. Problem-Items analysieren
python3 -c "
import json
from pathlib import Path
from collections import Counter

data = json.loads(Path('_OUTPUT/batch_review_remaining_issues_20251216_142834.json').read_text())

print(f'Total problem items: {len(data)}')

# H√§ufigste Problem-Gr√ºnde
reasons = [item.get('validation_summary', {}).get('reasoning', 'Unknown') for item in data]
print('\nTop Problem-Gr√ºnde:')
for reason, count in Counter(reasons).most_common(10):
    print(f'  {count:3d}x {reason[:80]}...')
"

# 2. Optional: Zweite Batch-Runde vorbereiten
python3 scripts/prepare_batch_review.py --filter-problems-only

# 3. Neue Outputs mit Timestamp schreiben
# NEU: _OUTPUT/batch_corrected_20251218_HHMMSS.json
# NEU: _OUTPUT/batch_validated_20251218_HHMMSS.json
```

**Wichtig:**
- Neue Outputs immer mit Timestamp
- Niemals `evidenz_antworten.json` √ºberschreiben
- Checkpoint-Files (.jsonl) f√ºr Resume-F√§higkeit

### üü° Dokumentation aktualisieren

**Dateien zu aktualisieren:**

1. **PROJECT_STATUS.md** - Auf Stand 2025-12-18 bringen
2. **TODO.md** - Aktuelle Aufgaben statt veraltete 2024-Tasks

**Vorgehen:**

```bash
# Basis: AGENT_OVERVIEW.md (bereits aktuell)
# Update PROJECT_STATUS.md mit:
# - Aktueller Datenstand (4.505 Q&A, 67 offene Issues)
# - Batch-Review Pipeline Status
# - Coverage 100% (meaningful)

# Update TODO.md mit:
# - 67 Problem-Items als h√∂chste Prio
# - Meaningful-Questions-Workflow (optional)
# - SRS-Exports aktualisieren
```

### üü¢ Optional: Meaningful Missing Questions

**Nur wenn explizit gew√ºnscht!**

**Authoritative Liste:** `_OUTPUT/meaningful_missing.json` (2.527 Eintr√§ge)
**Aktueller Coverage:** 2.527/2.527 = 100% ‚úÖ

**Coverage-Check:**

```bash
# Pr√ºfen ob alle meaningful questions bereits vorhanden sind
python3 -c "
import json
from pathlib import Path

mm = json.loads(Path('_OUTPUT/meaningful_missing.json').read_text())
qa = json.loads(Path('_OUTPUT/evidenz_antworten.json').read_text())

qa_fragen = set(x['frage'] for x in qa)
matched = sum(1 for x in mm if x['question'] in qa_fragen)

print(f'Meaningful Coverage: {matched}/{len(mm)} = {matched/len(mm)*100:.1f}%')
"
# Erwartet: 2527/2527 = 100.0%
```

**Wenn neue Fragen generiert werden sollen:**

```bash
# NUR meaningful verwenden, nicht strict!
python3 scripts/generate_evidenz_answers.py \
  --input _OUTPUT/meaningful_missing.json \
  --output _OUTPUT/evidenz_antworten_regen_$(date +%Y%m%d_%H%M%S).json \
  --batch-size 100
```

---

## üõ†Ô∏è Wichtige Commands (Copy & Paste)

### Setup-Checks

```bash
# 1. Ins Repo wechseln
cd /Users/entropie/Documents/Medexamenai_Migration/Medexamenai_migration_full_20251217_204617

# 2. venv aktivieren
source venv/bin/activate

# 3. Python-Version pr√ºfen
python3 --version  # Sollte: Python 3.x

# 4. Datenbank pr√ºfen
python3 -c "import json; print(len(json.load(open('_OUTPUT/evidenz_antworten.json'))))"
# Erwartete Ausgabe: 4505

# 5. API Keys pr√ºfen (ohne Werte anzuzeigen)
grep -c "^OPENAI_API_KEY=" .env && grep -c "^ANTHROPIC_API_KEY=" .env
# Sollte jeweils: 1
```

### Meaningful Coverage Check

```bash
# Vollst√§ndiger Coverage-Check
python3 -c "
import json
from pathlib import Path

mm = json.loads(Path('_OUTPUT/meaningful_missing.json').read_text())
qa = json.loads(Path('_OUTPUT/evidenz_antworten.json').read_text())

qa_set = set(x['frage'] for x in qa)
matched = sum(1 for x in mm if x['question'] in qa_set)

print(f'Coverage: {matched}/{len(mm)} = {matched/len(mm)*100:.1f}%')

if matched < len(mm):
    missing = [x for x in mm if x['question'] not in qa_set]
    print(f'\n{len(missing)} fehlende Fragen:')
    for m in missing[:5]:
        print(f'  - {m[\"question\"][:80]}...')
"
```

### needs_context Pakete

```bash
# 133 needs_context Items mit Kontext aus Goldstandard
python3 scripts/prepare_needs_context_packets.py

# Output:
# - _OUTPUT/needs_context_prepared_TIMESTAMP.json (133 Items mit Kontext)
# - _OUTPUT/needs_context_external_validation_TIMESTAMP.md (Liste f√ºr externe Pr√ºfung)
```

### Batch-Review Finalisierung (Re-Run)

```bash
# Falls zweite Batch-Runde f√ºr die 67 Problem-Items
python3 scripts/finalize_batch_review.py \
  --corrected _OUTPUT/batch_corrected_20251218_HHMMSS.json \
  --validated _OUTPUT/batch_validated_20251218_HHMMSS.json

# Output:
# - _OUTPUT/evidenz_antworten_updated_TIMESTAMP.json (NEU)
# - _OUTPUT/batch_review_report_TIMESTAMP.md
# - _OUTPUT/batch_review_remaining_issues_TIMESTAMP.json
```

### Lern-Exports (Anki + Dashboard)

```bash
# Anki TSV + Study Dashboard + Daily Plan
python3 scripts/export_learning_materials.py --daily-plan

# Output:
# - _OUTPUT/anki_ready_TIMESTAMP.tsv (f√ºr Anki Import)
# - _OUTPUT/anki_review_queue_TIMESTAMP.tsv (Review-Items)
# - _OUTPUT/study_dashboard_TIMESTAMP.md (√úbersicht)
# - _OUTPUT/daily_plan_TIMESTAMP.json (optional)
```

---

## üìÅ Wichtige Dateien & Pfade

### Dokumentation (Start hier)

| Datei | Zweck |
|-------|-------|
| [AGENT_OVERVIEW.md](AGENT_OVERVIEW.md) | üöÄ Agent-Schnelleinstieg (immer zuerst lesen!) |
| [PROJECT_STATUS.md](PROJECT_STATUS.md) | üìä Projektstatus & Milestones |
| [TODO.md](TODO.md) | ‚úÖ Priorisierte Aufgabenliste |
| [CODEX.md](CODEX.md) | üìù Kurzer Task-Briefing |
| [README.md](README.md) | üìñ Projekt-√úbersicht & Quick Start |
| [MIGRATION_GUIDE.md](MIGRATION_GUIDE.md) | üîÑ Migrations-Historie |

### Goldstandard-Quellen

| Pfad | Inhalt | Gr√∂√üe |
|------|--------|-------|
| `_GOLD_STANDARD/` | 40+ Pr√ºfungsprotokolle (PDF/DOCX/ODT) | ~150 MB |
| `_FACT_CHECK_SOURCES/` | AWMF-Leitlinien, Lehrmaterial | ~500 MB |
| `_DOCS/` | Zus√§tzliche Dokumentation | ~10 MB |

### Q&A Datenbank (READ-ONLY!)

| Datei | Eintr√§ge | Status |
|-------|----------|--------|
| `_OUTPUT/evidenz_antworten.json` | 4.505 | ‚õî READ-ONLY |
| `_OUTPUT/evidenz_antworten_updated_20251216_142834.json` | 4.505 | üìù Arbeitsdatei |

### Review-Queue

| Datei | Items | Beschreibung |
|-------|-------|--------------|
| `_OUTPUT/review_queue_20251216_033807.json` | 431 | needs_review + needs_context |
| `_OUTPUT/needs_context_prepared_20251216_054003.json` | 133 | Mit Kontext aus Goldstandard |
| `_OUTPUT/batch_review_remaining_issues_20251216_142834.json` | **67** | **Problem-Items (FOKUS!)** |

### Coverage-Referenzen

| Datei | Eintr√§ge | Status |
|-------|----------|--------|
| `_OUTPUT/meaningful_missing.json` | 2.527 | ‚úÖ Authoritative Liste (100% Coverage) |
| `_OUTPUT/questions_missing_strict.json` | 3.732 | ‚ùå Historisch, ignorieren! |

### Scripts (Wichtigste)

| Script | Zweck |
|--------|-------|
| `scripts/prepare_batch_review.py` | Batch-Review vorbereiten |
| `scripts/batch_correct_with_reasoning.py` | Antworten korrigieren (resumable) |
| `scripts/batch_validate_with_perplexity.py` | Web-Validierung (resumable) |
| `scripts/finalize_batch_review.py` | Ergebnisse finalisieren |
| `scripts/prepare_needs_context_packets.py` | needs_context mit Goldstandard-Kontext |
| `scripts/export_learning_materials.py` | Anki + Dashboard Exports |
| `scripts/generate_evidenz_answers.py` | Neue Q&A generieren |

---

## üé¨ Typische Workflows

### Workflow 1: 67 Problem-Items fixen

```bash
# 1. Problem-Items analysieren
python3 -c "
import json
from pathlib import Path

data = json.loads(Path('_OUTPUT/batch_review_remaining_issues_20251216_142834.json').read_text())
print(f'Problem Items: {len(data)}')

# Erste 3 Items anzeigen
for i, item in enumerate(data[:3], 1):
    print(f'\n{i}. {item[\"frage\"][:80]}...')
    print(f'   Problem: {item.get(\"validation_summary\", {}).get(\"reasoning\", \"N/A\")[:100]}')
"

# 2. Manuelle Korrektur ODER zweite Batch-Runde

# Option A: Manuell in neuem File
# (Niemals evidenz_antworten.json direkt editieren!)

# Option B: Zweite Batch-Runde
python3 scripts/batch_correct_with_reasoning.py --resume
python3 scripts/batch_validate_with_perplexity.py --resume
python3 scripts/finalize_batch_review.py

# 3. Neue Outputs validieren
ls -lh _OUTPUT/*$(date +%Y%m%d)*.json
```

### Workflow 2: Lern-Materialien exportieren

```bash
# 1. Aktuellen Stand pr√ºfen
python3 -c "
import json
from pathlib import Path

qa = json.loads(Path('_OUTPUT/evidenz_antworten.json').read_text())
ready = [x for x in qa if x.get('antwort', '').strip()]
review = [x for x in qa if x.get('needs_review') or x.get('needs_context')]

print(f'Ready f√ºr SRS: {len(ready)}')
print(f'In Review: {len(review)}')
"

# 2. Exports generieren
python3 scripts/export_learning_materials.py --daily-plan

# 3. Outputs pr√ºfen
ls -lh _OUTPUT/anki_ready_*.tsv
ls -lh _OUTPUT/study_dashboard_*.md
```

### Workflow 3: Coverage validieren

```bash
# Meaningful Coverage Check
python3 -c "
import json
from pathlib import Path

mm = json.loads(Path('_OUTPUT/meaningful_missing.json').read_text())
qa = json.loads(Path('_OUTPUT/evidenz_antworten.json').read_text())

qa_set = set(x['frage'] for x in qa)
matched = sum(1 for x in mm if x['question'] in qa_set)

print(f'Meaningful Coverage: {matched}/{len(mm)} ({matched/len(mm)*100:.1f}%)')

if matched == len(mm):
    print('‚úÖ 100% Coverage erreicht!')
else:
    print(f'‚ö†Ô∏è {len(mm) - matched} Fragen fehlen noch')
"
```

---

## üîç Debugging & Troubleshooting

### Problem: API Keys nicht gefunden

```bash
# Pr√ºfen ob .env existiert
ls -la .env

# Pr√ºfen ob Keys gesetzt sind (ohne Werte anzuzeigen)
grep -E "^(OPENAI|ANTHROPIC|PERPLEXITY)_API_KEY=" .env | wc -l
# Sollte: 3

# Wenn nicht gesetzt:
# 1. .env.example als Template verwenden
cp .env.example .env
# 2. Keys manuell eintragen (NIEMALS committen!)
```

### Problem: venv nicht gefunden

```bash
# venv neu erstellen
python3 -m venv venv

# Aktivieren
source venv/bin/activate

# Packages installieren
pip install -r requirements.txt
```

### Problem: JSON Parse Error

```bash
# JSON-Datei validieren
python3 -c "
import json
from pathlib import Path

try:
    data = json.loads(Path('DATEI.json').read_text())
    print(f'‚úÖ Valid JSON ({len(data)} items)')
except json.JSONDecodeError as e:
    print(f'‚ùå Invalid JSON: {e}')
"
```

### Problem: Script h√§ngt

```bash
# Checkpoint-File pr√ºfen (f√ºr resumable Scripts)
ls -lh _OUTPUT/*checkpoint.jsonl

# Script mit --resume neu starten
python3 scripts/SCRIPT_NAME.py --resume
```

---

## üìä Metriken & KPIs

### Datenbank-Metriken

```bash
python3 -c "
import json
from pathlib import Path

qa = json.loads(Path('_OUTPUT/evidenz_antworten.json').read_text())

total = len(qa)
with_answer = len([x for x in qa if x.get('antwort', '').strip()])
empty = total - with_answer
needs_review = len([x for x in qa if x.get('needs_review')])
needs_context = len([x for x in qa if x.get('needs_context')])

print(f'Total Q&A: {total}')
print(f'  Mit Antwort: {with_answer} ({with_answer/total*100:.1f}%)')
print(f'  Leer: {empty} ({empty/total*100:.1f}%)')
print(f'  needs_review: {needs_review}')
print(f'  needs_context: {needs_context}')
"
```

### Quality-Metriken

```bash
python3 -c "
import json
from pathlib import Path

# Batch-Review Status
report_path = Path('_OUTPUT/batch_review_report_20251216_142834.md')
if report_path.exists():
    print(report_path.read_text())
else:
    print('Kein Batch-Review-Report gefunden')
"
```

---

## üéØ N√§chste Schritte (Empfohlen)

### Diese Woche (2025-12-18 bis 2025-12-24)

1. **üî¥ H√ñCHSTE PRIO:** 67 Problem-Items aus `batch_review_remaining_issues` analysieren und fixen
   - H√§ufigste Problem-Gr√ºnde identifizieren
   - Systematische Korrektur-Strategie entwickeln
   - Zweite Batch-Runde durchf√ºhren ODER manuelle Korrektur

2. **üü° DOKU:** PROJECT_STATUS.md und TODO.md aktualisieren
   - Aktueller Stand (4.505 Q&A, 67 offene Issues)
   - Batch-Review Pipeline Status
   - Coverage 100% dokumentieren

3. **üü¢ OPTIONAL:** Lern-Exports aktualisieren
   - Neue Anki-TSVs generieren
   - Study Dashboard aktualisieren
   - Daily Plan erstellen

### N√§chste Woche (2025-12-25 bis 2025-12-31)

1. **Empty Answers Workflow** (falls noch leer)
   - Leere Antworten identifizieren
   - Batch-Generierung durchf√ºhren
   - Qualit√§ts-Validierung

2. **SRS Integration** finalisieren
   - Spaced Repetition Algorithmus testen
   - Mentor Agent Integration vorbereiten

3. **Medical Validation Pass** durchf√ºhren
   - Stichprobe von 100 Q&A
   - Medizinische Fakten-Checks
   - Dosierungen validieren

---

## ‚ö†Ô∏è Wichtige Erinnerungen

### DON'Ts (Niemals tun!)

- ‚ùå `_OUTPUT/evidenz_antworten.json` direkt editieren oder √ºberschreiben
- ‚ùå Secrets/API-Keys loggen, committen oder anzeigen
- ‚ùå `questions_missing_strict.json` verwenden (veraltet!)
- ‚ùå Ohne venv arbeiten (`source venv/bin/activate`)
- ‚ùå Outputs ohne Timestamp schreiben

### DOs (Immer tun!)

- ‚úÖ AGENT_OVERVIEW.md zuerst lesen
- ‚úÖ venv aktivieren vor jedem Script
- ‚úÖ Neue Outputs mit Timestamp schreiben
- ‚úÖ Checkpoint-Files (.jsonl) f√ºr Resume nutzen
- ‚úÖ `meaningful_missing.json` f√ºr Coverage verwenden

---

## üìö Weitere Ressourcen

| Ressource | Pfad/Link |
|-----------|-----------|
| Vollst√§ndiger Handover | [COMPLETE_HANDOVER.md](COMPLETE_HANDOVER.md) |
| CODEX Handover (2025-12-01) | [CODEX_HANDOVER_2025-12-01.md](CODEX_HANDOVER_2025-12-01.md) |
| Entwickler-Guide | [DEVELOPMENT.md](DEVELOPMENT.md) |
| Migration History | [MIGRATION_GUIDE.md](MIGRATION_GUIDE.md) |
| Scripts √úbersicht | [scripts/](scripts/) |

---

## ‚úÖ Pre-Flight Checklist (Vor dem Start)

```bash
# 1. Repo-Pfad
pwd
# Sollte: /Users/entropie/Documents/Medexamenai_Migration/Medexamenai_migration_full_20251217_204617

# 2. venv aktiv?
which python3
# Sollte: .../venv/bin/python3

# 3. Datenbank vorhanden?
ls -lh _OUTPUT/evidenz_antworten.json
# Sollte: ~11M

# 4. API Keys gesetzt?
grep -c "^OPENAI_API_KEY=" .env && grep -c "^ANTHROPIC_API_KEY=" .env
# Sollte jeweils: 1

# 5. Wichtige Dateien gelesen?
# [ ] AGENT_OVERVIEW.md
# [ ] PROJECT_STATUS.md
# [ ] TODO.md
# [ ] Diese Datei

# Wenn alle ‚úÖ: Ready to go! üöÄ
```

---

**Ende des Cursor Agent Prompts**

Bei Fragen oder Problemen:
- Konsultiere [AGENT_OVERVIEW.md](AGENT_OVERVIEW.md)
- Pr√ºfe [PROJECT_STATUS.md](PROJECT_STATUS.md)
- Schaue in [TODO.md](TODO.md)

**Viel Erfolg! üéì**
