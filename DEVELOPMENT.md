# ðŸ› ï¸ Development Guide - MedExamAI

## Inhaltsverzeichnis

- [Setup](#setup)
- [Architektur](#architektur)
- [Coding Standards](#coding-standards)
- [Testing](#testing)
- [Git Workflow](#git-workflow)
- [Common Tasks](#common-tasks)
- [Automated Reviews](#automated-reviews)

---

## Setup

### Voraussetzungen

```bash
# Python 3.11+
python3 --version

# Git
git --version
```

### Lokales Setup

```bash
# 1. Repository klonen
cd ~/Documents/Medexamenai

# 2. Virtual Environment (optional, aber empfohlen)
python3 -m venv .venv
source .venv/bin/activate  # macOS/Linux
# oder: .venv\Scripts\activate  # Windows

# 3. Dependencies installieren
pip install -r requirements.txt

# 4. Config validieren
python3 -c "import yaml; print(yaml.safe_load(open('config.yaml')))"
```

### requirements.txt

```txt
pypdf>=3.17.0
python-docx>=1.1.0
pyyaml>=6.0.1

# Optional - fÃ¼r erweiterte Features
pytesseract>=0.3.10  # OCR fÃ¼r gescannte PDFs
```

---

## Architektur

### Design-Prinzipien

1. **KISS** - Keep It Simple, Stupid
2. **Single Responsibility** - Jedes Skript hat genau eine Aufgabe
3. **Stateless** - Keine komplexen State-Files
4. **Transparent** - Jede Datei kennt ihre Herkunft (`source_file`, `source_tier`)

### Pipeline-Ãœbersicht

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 1: EXTRAKTION                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input:  _GOLD_STANDARD/*.{pdf,docx}                     â”‚
â”‚ Tool:   scripts/extract_dialog_blocks.py                â”‚
â”‚ Output: _EXTRACTED_FRAGEN/frage_bloecke.json            â”‚
â”‚                                                          â”‚
â”‚ Funktion: Extrahiert echte PrÃ¼fungsfragen in BlÃ¶cken   â”‚
â”‚           mit Patientenkontext (F:, A: Pattern)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 2: ANTWORT-GENERIERUNG                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input:  _EXTRACTED_FRAGEN/frage_bloecke.json            â”‚
â”‚ Tool:   scripts/generate_answers.py                     â”‚
â”‚ Output: _OUTPUT/qa_gold_standard.json                   â”‚
â”‚                                                          â”‚
â”‚ Funktion: Generiert Antworten im 5-Punkte-Schema       â”‚
â”‚           basierend auf Leitlinien (AWMF, ESC, DGK)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 3: MEDICAL VALIDATION                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input:  _OUTPUT/qa_gold_standard.json                   â”‚
â”‚ Tool:   scripts/validate_medical.py                     â”‚
â”‚ Output: _OUTPUT/_validated/qa_validated.json            â”‚
â”‚                                                          â”‚
â”‚ Funktion: 4 PrÃ¼fer (Dosage, ICD-10, Lab, Logic)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 4: EXPORT                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input:  _OUTPUT/_validated/qa_validated.json            â”‚
â”‚ Tool:   scripts/export.py                               â”‚
â”‚ Output: Anki-Karten, PDF, etc.                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Datenfluss-Diagramm

```
_GOLD_STANDARD/
    â”‚
    â”œâ”€â”€ *.pdf      â”€â”
    â”œâ”€â”€ *.docx     â”€â”¼â”€â”€> extract_dialog_blocks.py
    â””â”€â”€ *.txt      â”€â”˜
                     â”‚
                     â†“
            _EXTRACTED_FRAGEN/
              frage_bloecke.json
                     â”‚
                     â†“
            generate_answers.py
                     â”‚
                     â†“
              _OUTPUT/
         qa_gold_standard.json
                     â”‚
                     â†“
            validate_medical.py
                     â”‚
                     â†“
           _OUTPUT/_validated/
            qa_validated.json
                     â”‚
                     â†“
              export.py
                     â”‚
                     â†“
          Anki/PDF/Web
```

---

## Coding Standards

### Python Style

Wir folgen **PEP 8** mit einigen Ausnahmen:

```python
# âœ… Gut
def extract_questions(pdf_path: Path) -> List[Question]:
    """Extrahiert Fragen aus einem PDF.
    
    Args:
        pdf_path: Pfad zum PDF
        
    Returns:
        Liste von Question-Objekten
    """
    questions = []
    # ...
    return questions

# âŒ Schlecht
def extractQuestions(pdfPath):
    qs = []
    # ...
    return qs
```

### Docstrings

```python
def process_document(
    file_path: Path,
    context_lines: int = 6
) -> Dict[str, Any]:
    """Verarbeitet ein Dokument und extrahiert Frage-BlÃ¶cke.
    
    Args:
        file_path: Pfad zum Dokument (PDF, DOCX, TXT)
        context_lines: Anzahl der Kontext-Zeilen vor jeder Frage
        
    Returns:
        Dictionary mit:
            - block_id: Eindeutige ID
            - questions: Liste von Fragen
            - context: Kontext-Text
            
    Raises:
        FileNotFoundError: Wenn Datei nicht existiert
        ValueError: Wenn Datei-Format nicht unterstÃ¼tzt
    """
    pass
```

### Type Hints

**Immer** Type Hints verwenden:

```python
from typing import List, Dict, Optional, Tuple
from pathlib import Path

# âœ… Gut
def load_config(path: Path) -> Dict[str, str]:
    pass

# âŒ Schlecht
def load_config(path):
    pass
```

### Error Handling

```python
# âœ… Gut - Spezifische Exceptions
try:
    data = json.load(open(file_path))
except FileNotFoundError:
    print(f"âŒ Datei nicht gefunden: {file_path}")
    return None
except json.JSONDecodeError as e:
    print(f"âŒ UngÃ¼ltiges JSON: {e}")
    return None

# âŒ Schlecht - Generische Exception
try:
    data = json.load(open(file_path))
except Exception as e:
    print(f"Error: {e}")
```

### Logging

```python
# âœ… Gut - Strukturiertes Logging
def extract_questions(pdf_path: Path) -> List[Question]:
    print(f"ðŸ“„ Verarbeite: {pdf_path.name}")
    questions = []
    
    for idx, page in enumerate(pages):
        print(f"   Seite {idx + 1}/{total_pages}...", end='\r')
        # ...
    
    print(f"âœ… {len(questions)} Fragen extrahiert")
    return questions

# âŒ Schlecht - Keine Ausgabe
def extract_questions(pdf_path):
    questions = []
    # ...
    return questions
```

---

## Testing

### Test-Struktur

```
tests/
â”œâ”€â”€ test_extract_questions.py
â”œâ”€â”€ test_extract_dialog_blocks.py
â”œâ”€â”€ test_generate_answers.py
â””â”€â”€ fixtures/
    â”œâ”€â”€ sample.pdf
    â””â”€â”€ expected_output.json
```

### Beispiel-Test

```python
# tests/test_extract_questions.py
import pytest
from pathlib import Path
from scripts.extract_questions import extract_from_pdf, Question

def test_extract_simple_question():
    """Test: Einfache Frage wird korrekt extrahiert."""
    # Arrange
    pdf_path = Path("tests/fixtures/sample.pdf")
    
    # Act
    questions = list(extract_from_pdf(pdf_path))
    
    # Assert
    assert len(questions) > 0
    assert isinstance(questions[0], Question)
    assert questions[0].source_tier == "gold_standard"

def test_extract_no_hallucination():
    """Test: Keine fiktiven Cases werden erfunden."""
    pdf_path = Path("tests/fixtures/sample.pdf")
    questions = list(extract_from_pdf(pdf_path))
    
    # Alle Fragen mÃ¼ssen aus dem PDF stammen
    for q in questions:
        assert q.source_file == pdf_path.name
        assert q.frage.endswith("?")
```

### Tests ausfÃ¼hren

```bash
# Alle Tests
pytest tests/ -v

# Einzelner Test
pytest tests/test_extract_questions.py::test_extract_simple_question -v

# Mit Coverage
pytest --cov=scripts tests/

# Nur schnelle Tests (keine Integration)
pytest tests/ -m "not slow"
```

---

## Git Workflow

### Branch-Strategie

```bash
main                    # Production-ready code
  â”œâ”€â”€ feature/extract-dialog-blocks
  â”œâ”€â”€ feature/answer-generation
  â””â”€â”€ fix/dosage-validation
```

### Commit-Konventionen

```bash
# Format: <type>(<scope>): <subject>

# Types:
feat:     Neues Feature
fix:      Bugfix
docs:     Dokumentation
style:    Formatierung (keine Code-Ã„nderung)
refactor: Code-Refactoring
test:     Tests hinzufÃ¼gen/Ã¤ndern
chore:    Build/Setup

# Beispiele:
git commit -m "feat(extraction): Add dialog block extraction with context"
git commit -m "fix(dosage): Validate mg/kg dosages correctly"
git commit -m "docs(readme): Update quick start guide"
```

### Pre-Commit Checklist

Vor jedem Commit:

```bash
# 1. Code formatieren (optional)
black scripts/

# 2. Linting (optional)
pylint scripts/*.py

# 3. Tests laufen
pytest tests/ -v

# 4. Commit
git add .
git commit -m "feat(extraction): Add new feature"
git push
```

---

## Common Tasks

### Neue Frage-Extraktion hinzufÃ¼gen

```bash
# 1. Feature-Branch erstellen
git checkout -b feature/new-extraction-pattern

# 2. Code Ã¤ndern
# scripts/extract_dialog_blocks.py

# 3. Test hinzufÃ¼gen
# tests/test_extract_dialog_blocks.py

# 4. Testlauf
pytest tests/test_extract_dialog_blocks.py -v

# 5. Commit & Push
git add scripts/ tests/
git commit -m "feat(extraction): Add new pattern for XYZ"
git push origin feature/new-extraction-pattern
```

### Neue Klassifikation hinzufÃ¼gen

```python
# 1. In scripts/generate_answers.py (oder separates config file)
KLASSIFIKATIONEN = {
    # ... bestehende ...
    "neue_erkrankung": "Name der Klassifikation",
}

# 2. Test schreiben
def test_new_classification():
    # ...
    
# 3. Dokumentieren in README
```

### Debug-Modus

```python
# FÃ¼ge am Anfang des Skripts hinzu:
import logging
logging.basicConfig(level=logging.DEBUG)

# Dann im Code:
logging.debug(f"Variable x = {x}")
logging.info(f"Processing {filename}")
logging.warning(f"Unexpected value: {value}")
logging.error(f"Failed to process: {error}")
```

### Performance-Profiling

```python
import time

start = time.time()
# ... code ...
end = time.time()
print(f"â±ï¸ Verarbeitung dauerte {end - start:.2f}s")
```

---

## Troubleshooting

### Problem: pypdf kann PDF nicht lesen

```bash
# LÃ¶sung 1: OCR verwenden
pip install pytesseract
# Dann in Code: ocr_fallback=True

# LÃ¶sung 2: PDF konvertieren
# Nutze Adobe Acrobat oder online-tools
```

### Problem: Zu viele/zu wenige Fragen extrahiert

```python
# Debug: Zeige erkannte Pattern
def extract_questions(..., debug=True):
    if debug:
        print(f"Pattern matches: {matches}")
        print(f"Context: {context}")
```

### Problem: Encoding-Fehler

```python
# Immer UTF-8 verwenden
with open(file_path, 'r', encoding='utf-8') as f:
    data = f.read()
```

---

## Best Practices

### 1. NIEMALS fiktive Cases erfinden

```python
# âŒ FALSCH
if "Pankreatitis" in text:
    case = generate_fake_case("Pankreatitis")  # VERBOTEN!

# âœ… RICHTIG
if "F:" in line:
    question = extract_literal_question(line)
```

### 2. Immer Tier taggen

```python
# âœ… RICHTIG
question = {
    "frage": "...",
    "source_tier": "gold_standard",  # PFLICHT!
    "source_file": "protokoll.pdf"
}
```

### 3. Backup vor Ã„nderungen

```python
def safe_process(input_file: Path, output_file: Path):
    # Backup erstellen
    if output_file.exists():
        backup = output_file.with_suffix('.json.backup')
        shutil.copy(output_file, backup)
        print(f"ðŸ’¾ Backup: {backup}")
    
    # Dann Verarbeitung
    result = process(input_file)
    output_file.write_text(json.dumps(result, indent=2))
```

### 4. Validierung nach Filter

```python
def safe_filter(original: List, filtered: List, operation: str) -> bool:
    loss_percent = (1 - len(filtered) / len(original)) * 100
    
    if loss_percent > 90:
        print(f"ðŸš¨ KRITISCH: {operation} entfernt {loss_percent:.1f}%!")
        return False
    
    return True
```

---

## NÃ¤chste Schritte

1. [ ] `generate_answers.py` implementieren
2. [ ] `validate_medical.py` implementieren
3. [ ] `export.py` implementieren
4. [ ] Tests fÃ¼r alle Skripte schreiben
5. [ ] CI/CD Setup (GitHub Actions)
6. [ ] Jira-Integration dokumentieren

---

## Hilfreiche Links

- [Python Type Hints](https://docs.python.org/3/library/typing.html)
- [pytest Documentation](https://docs.pytest.org/)
- [PEP 8 Style Guide](https://pep8.org/)
- [Git Commit Conventions](https://www.conventionalcommits.org/)

---

## Automated Reviews

1. **AI Reviewer Workflow**
   - Workflow-Datei: `.github/workflows/ai-reviews.yml`
   - Trigger: PR Events (`opened`, `synchronize`, `reopened`) sowie Issue-Kommentare mit `@claude`, `@gemini`, `@ai-review`.
   - Claude nutzt `ANTHROPIC_API_KEY`, Gemini `GOOGLE_AI_API_KEY`. Ohne Keys werden Hinweise im Log ausgegeben.
   - Kommentare werden Ã¼ber die GitHub REST API gepostet, damit keine YAML-Quote-Probleme entstehen.

2. **CI Quality Gate**
   - Workflow: `.github/workflows/ci.yml`
   - Jobs `test` und `safety-check` mÃ¼ssen bestehen; das Job `quality-gate` aggregiert die Ergebnisse und schlÃ¤gt fehl, wenn ein Check rot ist.
   - Branch Protection kann auf das `Quality Gate Summary`-Resultat verweisen.

3. **Manual Fallbacks**
   - GitHub Apps (Copilot PRs, CodeRabbit, Gemini for GitHub) kÃ¶nnen ohne API-Key installiert werden.
   - Reviewer kÃ¶nnen `@ai-review` kommentieren, um Hinweise zu erhalten (auch wenn keine Secrets konfiguriert sind).

4. **Setup Checklist**
   - [ ] Secrets in GitHub: `ANTHROPIC_API_KEY`, `GOOGLE_AI_API_KEY`, `CODECOV_TOKEN`.
   - [ ] Optional: `CODECOV_TOKEN` (Coverage Upload) aktivieren.
   - [ ] Branch Protection Regel erstellt mit `Required status checks: Tests, Safety & Security, Quality Gate Summary`.
   - [ ] Team informiert (siehe README Abschnitt "Automated Code Reviews & Quality Gate").

---

**Letzte Aktualisierung:** 2024-12-01
